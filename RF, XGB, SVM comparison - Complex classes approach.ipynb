{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest vs XGBoost vs SVM with complex classes based on confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook evaluates the performance of three classifiers: **Random Forest**, **XGBoost** and **SVM**. These classifiers use both **Sentiment** and sentiment **Confidence**, by splitting the dataset into buckets. The target classes are:\n",
    "\n",
    "- *Highly Positive*: positive sentiment and confidence **> threshold**\n",
    "- *Slightly Positive*: positive sentiment and confidence **≤ threshold**\n",
    "- *Highly Negative*: negative sentiment and confidence **> threshold**\n",
    "- *Slightly Negative*: negative sentiment and confidence **≤ threshold**\n",
    "- *Neutral / author is just sharing information*\n",
    "- *Tweet not related to weather condition*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.WeatherSentimentData import WeatherSentimentData\n",
    "from src.TweetTextPreprocessor import TweetTextPreprocessor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from config import threshold, test_size, saved_models_path, saved_vectorizers_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative                                        429\n",
      "Positive                                        403\n",
      "Neutral / author is just sharing information    391\n",
      "Tweet not related to weather condition          348\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8439</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Grilling kabobs on the grill last night was am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6963</td>\n",
       "      <td>Negative</td>\n",
       "      <td>The slowest day ever !! And the weather makes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8802</td>\n",
       "      <td>Neutral / author is just sharing information</td>\n",
       "      <td>Fire Weather Watch issued May 17 at 4:21PM CDT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6897</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Im going to lunch early today.   The weather i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6153</td>\n",
       "      <td>Neutral / author is just sharing information</td>\n",
       "      <td>Weekend Weather Causes Delays In I-270 Bridge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>0.6012</td>\n",
       "      <td>Neutral / author is just sharing information</td>\n",
       "      <td>@mention You're welcome. I'm glad you enjoyed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>0.7821</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Going skiing with my buddies. It's going to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>0.7194</td>\n",
       "      <td>Negative</td>\n",
       "      <td>This humidity is unbearable. I feel like I'm i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>0.6389</td>\n",
       "      <td>Tweet not related to weather condition</td>\n",
       "      <td>Look at this cute puppy I found on the street....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>0.7643</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Feeling cozy in my new sweater. It's so soft a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      confidence                                     sentiment  \\\n",
       "0         0.8439                                      Positive   \n",
       "1         0.6963                                      Negative   \n",
       "2         0.8802  Neutral / author is just sharing information   \n",
       "3         0.6897                                      Positive   \n",
       "4         0.6153  Neutral / author is just sharing information   \n",
       "...          ...                                           ...   \n",
       "1566      0.6012  Neutral / author is just sharing information   \n",
       "1567      0.7821                                      Positive   \n",
       "1568      0.7194                                      Negative   \n",
       "1569      0.6389        Tweet not related to weather condition   \n",
       "1570      0.7643                                      Positive   \n",
       "\n",
       "                                             tweet_text  \n",
       "0     Grilling kabobs on the grill last night was am...  \n",
       "1     The slowest day ever !! And the weather makes ...  \n",
       "2     Fire Weather Watch issued May 17 at 4:21PM CDT...  \n",
       "3     Im going to lunch early today.   The weather i...  \n",
       "4     Weekend Weather Causes Delays In I-270 Bridge ...  \n",
       "...                                                 ...  \n",
       "1566  @mention You're welcome. I'm glad you enjoyed ...  \n",
       "1567  Going skiing with my buddies. It's going to be...  \n",
       "1568  This humidity is unbearable. I feel like I'm i...  \n",
       "1569  Look at this cute puppy I found on the street....  \n",
       "1570  Feeling cozy in my new sweater. It's so soft a...  \n",
       "\n",
       "[1571 rows x 3 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data = WeatherSentimentData('data', use_generated_data=True)\n",
    "df = weather_data.full_data\n",
    "print(df.sentiment.value_counts())\n",
    "df[['confidence', 'sentiment', 'tweet_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text preprocessing consists of 5 stages:\n",
    "- converting all letters to lowercase,\n",
    "- removing all unnecessary elements (urls, @mentions, nonwords, digits etc.)\n",
    "- tokenizing the text,\n",
    "- excluding stopwords,\n",
    "- stemming\n",
    "\n",
    "Its code can be fined in [text-preprocessing.ipynb](text-preprocessing.ipynb) or in [TweetTextPreprocessor.py](src/TweetTextPreprocessor.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mmakaranka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mmakaranka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mmakaranka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mmakaranka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "preprocessor = TweetTextPreprocessor()\n",
    "df['tweet_text'] = preprocessor.preprocess(df['tweet_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming Sentiment column so tweets with *Positive* sentiment are split into *Highly positive* and *Slightly positive* and with *Negative* sentiment are split into *Highly negative* and *Slightly negative*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral / author is just sharing information    391\n",
       "Tweet not related to weather condition          348\n",
       "Highly positive                                 302\n",
       "Highly negative                                 275\n",
       "Slightly negative                               154\n",
       "Slightly positive                               101\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new classes\n",
    "df['sentiment'] = df.apply(lambda row: \"Highly positive\" if (row['sentiment'] == 'Positive' and row[\"confidence\"] > threshold) else row['sentiment'], axis=1)\n",
    "df['sentiment'] = df.apply(lambda row: \"Slightly positive\" if (row['sentiment'] == 'Positive' and row[\"confidence\"] <= threshold) else row['sentiment'], axis=1)\n",
    "df['sentiment'] = df.apply(lambda row: \"Highly negative\" if (row['sentiment'] == 'Negative' and row[\"confidence\"] > threshold) else row['sentiment'], axis=1)\n",
    "df['sentiment'] = df.apply(lambda row: \"Slightly negative\" if (row['sentiment'] == 'Negative' and row[\"confidence\"] <= threshold) else row['sentiment'], axis=1)\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits the data into training and test sets. `X` consists of preprocessed tweets, `y` holds assigned sentiment classes, `w` keeps weights (confidence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_text'] = df['tweet_text'].apply(lambda x: ' '.join(x)) # list -> string\n",
    "X = df['tweet_text']\n",
    "y = df['sentiment']\n",
    "w = df['confidence']\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, w, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our vectorizer of choice is going to be a **Term Frequency-Inverse Document Frequency** with n-grams of words within the range of 1 to 3 (unigrams, bigrams, and trigrams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram\n",
    "tf_idf_ngram_vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "X_tf_idf_word_train = tf_idf_ngram_vectorizer.fit_transform(X_train)\n",
    "X_tf_idf_word_test = tf_idf_ngram_vectorizer.transform(X_test)\n",
    "\n",
    "with open(path.join(saved_vectorizers_path, 'complex_classes_vectorizer.pkl'), 'wb') as file:\n",
    "    pickle.dump(tf_idf_ngram_vectorizer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding for XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because **XGBoost** algorithm cannot deal with categorical variables on its own we need label encoding to transform Sentiment values (strings) into plain integers. We also save our label encoder to file as it will be needed for future endeavours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "with open(path.join(saved_vectorizers_path, 'complex_classes_label_encoder.pkl'), 'wb') as file:\n",
    "    pickle.dump(label_encoder, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing and fitting random forest algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_tf_idf_word_train, y_train, w_train)\n",
    "\n",
    "with open(path.join(saved_models_path, \"rf_complex_classes.pkl\"), 'wb') as file:\n",
    "    pickle.dump(rf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for test set and counting predicted classes complemented with test set accuracy and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet not related to weather condition          44\n",
       "Highly positive                                 40\n",
       "Neutral / author is just sharing information    30\n",
       "Highly negative                                 25\n",
       "Slightly negative                               18\n",
       "Slightly positive                                1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rf = rf.predict(X_tf_idf_word_test)\n",
    "pd.Series(y_pred_rf).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy', 0.5443037974683544)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Accuracy\", accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              precision    recall  f1-score   support\n",
      "\n",
      "                             Highly negative       0.60      0.56      0.58        27\n",
      "                             Highly positive       0.65      0.81      0.72        32\n",
      "Neutral / author is just sharing information       0.53      0.52      0.52        31\n",
      "                           Slightly negative       0.28      0.22      0.24        23\n",
      "                           Slightly positive       1.00      0.07      0.13        14\n",
      "      Tweet not related to weather condition       0.52      0.74      0.61        31\n",
      "\n",
      "                                    accuracy                           0.54       158\n",
      "                                   macro avg       0.60      0.49      0.47       158\n",
      "                                weighted avg       0.57      0.54      0.52       158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr_rf = classification_report(y_test, y_pred_rf)\n",
    "print(cr_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same fitting, predicting and metrics gathering process will be repeated for both **XGBoost** and **SVM**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mmakaranka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:727: FutureWarning: Pass `sample_weight` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=42)\n",
    "xgb.fit(X_tf_idf_word_train, y_train_encoded, w_train)\n",
    "\n",
    "with open(path.join(saved_models_path, \"xgb_complex_classes.pkl\"), 'wb') as file:\n",
    "    pickle.dump(xgb, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Highly positive                                 47\n",
       "Tweet not related to weather condition          37\n",
       "Highly negative                                 29\n",
       "Neutral / author is just sharing information    24\n",
       "Slightly negative                               18\n",
       "Slightly positive                                3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_xgb = xgb.predict(X_tf_idf_word_test)\n",
    "y_pred_xgb = label_encoder.inverse_transform(y_pred_xgb)\n",
    "pd.Series(y_pred_xgb).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy', 0.5)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Accuracy\", accuracy_score(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              precision    recall  f1-score   support\n",
      "\n",
      "                             Highly negative       0.45      0.48      0.46        27\n",
      "                             Highly positive       0.57      0.84      0.68        32\n",
      "Neutral / author is just sharing information       0.62      0.48      0.55        31\n",
      "                           Slightly negative       0.28      0.22      0.24        23\n",
      "                           Slightly positive       0.00      0.00      0.00        14\n",
      "      Tweet not related to weather condition       0.51      0.61      0.56        31\n",
      "\n",
      "                                    accuracy                           0.50       158\n",
      "                                   macro avg       0.41      0.44      0.42       158\n",
      "                                weighted avg       0.46      0.50      0.47       158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr_xgb = classification_report(y_test, y_pred_xgb)\n",
    "print(cr_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=42)\n",
    "svm.fit(X_tf_idf_word_train, y_train, w_train)\n",
    "\n",
    "with open(path.join(saved_models_path, \"svm_complex_classes.pkl\"), 'wb') as file:\n",
    "    pickle.dump(svm, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet not related to weather condition          59\n",
       "Highly positive                                 52\n",
       "Neutral / author is just sharing information    28\n",
       "Highly negative                                 19\n",
       "dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_svm = svm.predict(X_tf_idf_word_test)\n",
    "pd.Series(y_pred_svm).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy', 0.5379746835443038)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Accuracy\", accuracy_score(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              precision    recall  f1-score   support\n",
      "\n",
      "                             Highly negative       0.74      0.52      0.61        27\n",
      "                             Highly positive       0.56      0.91      0.69        32\n",
      "Neutral / author is just sharing information       0.64      0.58      0.61        31\n",
      "                           Slightly negative       0.00      0.00      0.00        23\n",
      "                           Slightly positive       0.00      0.00      0.00        14\n",
      "      Tweet not related to weather condition       0.41      0.77      0.53        31\n",
      "\n",
      "                                    accuracy                           0.54       158\n",
      "                                   macro avg       0.39      0.46      0.41       158\n",
      "                                weighted avg       0.44      0.54      0.47       158\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mmakaranka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mmakaranka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mmakaranka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cr_svm = classification_report(y_test, y_pred_svm)\n",
    "print(cr_svm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
